---
title: "Kaggleのハードルを下げたい！"
source: "https://qiita.com/Isaka-code/items/3935cdb2a0bda331e07c"
author:
  - "[[Isaka-code]]"
published: 2023-10-16
created: 2025-07-29
description:
tags:
  - "clippings"
  - "Kaggle"
---
![](https://relay-dsp.ad-m.asia/dmp/sync/bizmatrix?pid=c3ed207b574cf11376&d=x18o8hduaj&uid=4098794)

[![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2627015/99fbe91c-6a6f-88de-91c9-0f7bc07fb8e0.png)](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F2627015%2F99fbe91c-6a6f-88de-91c9-0f7bc07fb8e0.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=14567071bc3af6fab64f561eb03efd2f)

*Image generated by OpenAI's DALL·E-3.*

## はじめに

こんにちは！  
突然ですが、Kaggleのハードルって高くないですか？特に初見だと、複雑なルールや大量のデータなどに圧倒されてしまう人も多いかもしれませんね。また、全て英語なので非英語話者にとってはそこもハードルを上げる原因になっていると考えられます。実際は慣れれば簡単なことも多いのですが、Kaggle慣れするまでにやや時間がかかるのも事実です。そこで、少しでもKaggleのハードルを下げたいと考えて本記事を執筆しました。

### 対象読者様

この記事は、以下のような方をメインに想定して執筆しました。

- AI・データ分析・機械学習に興味があって、Kaggleに参加しようと思ったけどハードルが高くて躊躇している方
- Kaggleに参加したはいいものの、ドロップアウトしてしまった方
- Kaggleのハードルを乗り越えたい方

### Kaggleのハードルを分解してみる

Kaggleのハードルは以下の段階があると思います。まずは、ステップごとにハードルを下げる方法を紹介します。

1. 登録のハードル
2. チュートリアル参加のハードル
3. 賞金付きコンペティション参加のハードル
4. 最初の提出までのハードル
5. 自力でのNotebook作成までのハードル
6. メダル獲得のハードル
7. （上位入賞のハードル）

#### 1\. 登録のハードルを下げる

Kaggleの登録方法については下記のサイトがわかりやすいです。

#### 2\. チュートリアル参加のハードルを下げる

Kaggleには有名なチュートリアルコンペティションとして"Titanicコンペ"があります。

その他にも"Active", "Getting Started"でフィルタリングすると、入門者向けでアクティブなコンペティションが見つかります。

チュートリアル参加のハードルを下げるためには、有名Kagglerのu++さんの記事がとても丁寧でわかりやすいです。Kaggle登録後は、まずはこの記事の分析手順に倣うのがおすすめです。

#### 3\. 賞金付きコンペティション参加のハードルを下げる

Kaggleのユーザー数は1500万人を超えていますが、Kaggle Rankings（Competitions）に名前があるユーザー数（≒賞金付きコンペティション参加経験者）は約20万人に留まります。チュートリアルコンペに参加後に離脱してしまう方が多いと推察されます。

こちらのハードルを下げる方法はシンプルで、開催中のコンペティションで面白そうなものを選び、”Join Competition”ボタンを押すだけです。

特に正解はないのですが、入門を突破するにあたって、参考になりそうな記事を2件共有します。

もし英語が原因でハードルを感じる場合は、国産コンペティションに参加することもおすすめです。

#### 4\. 最初の提出までのハードルを下げる

無事参加した後にも、最初の提出までのハードルがあります。  
解決策としては、公開されているNotebookでVote数が多いものを使う（Getting Started、Quick Startなど入門向けとわかる名前がついていることが多いです）のがおすすめです。とりあえずリーダーボードに名前を載せることは、モチベーション維持のためにも良いです。  
公開Notebookで良さそうのものを少し変更したりすることから理解を深めていけば良いと思います。

#### 5\. 自力でのNotebook作成までのハードルを下げる

公開Notebookを使用して提出までこぎつけれるようになった後も、自力でのNotebook作成のハードルがあります。  
コンペティションのルールを読み解いたり、データを読み込んで確認したり、地道な作業を通して提出までできるNotebookを作成します。英語がわからない場合は翻訳ツールを使い、ソースコード作成の補助には生成AIツールを使うなど文明の利器に頼ることも有効と考えられます。もちろん、機械学習について勉強し、Pythonや各種データ分析用ライブラリの扱いに習熟することも重要です。

#### 6\. メダル獲得のハードルを下げる

自力でのNotebook作成ができるようになれば、メダル獲得は間近です。所感としては、 [**「Kaggleで勝つデータ分析の技術」**](https://www.amazon.co.jp/Kaggle%E3%81%A7%E5%8B%9D%E3%81%A4%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%AE%E6%8A%80%E8%A1%93-%E9%96%80%E8%84%87-%E5%A4%A7%E8%BC%94/dp/4297108437) に書かれているような、ある種のデータ分析の王道ともいえる内容を適切に積み重ねていけば、メダルの獲得は難しくないと感じています。  
ちなみに、メダル2枚でKaggle Competitions Expertになることができるので、最初の目標として良いと思います。Kaggle Competitions Expertになることができた日は、飛び上がるほど嬉しかったのを覚えています。

#### 7\. （上位入賞のハードルを下げる）

上位入賞には、高度な分析力とハードワークが求められます。正解はないと思いますが、色々と調べていると原則みたいなものはあるようです。

[**「The Kaggle Book：データ分析競技 実践ガイド＆精鋭31人インタビュー」**](https://www.amazon.co.jp/Kaggle-Book%EF%BC%9A%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E7%AB%B6%E6%8A%80-%E5%AE%9F%E8%B7%B5%E3%82%AC%E3%82%A4%E3%83%89%EF%BC%86%E7%B2%BE%E9%8B%AD31%E4%BA%BA%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%93%E3%83%A5%E3%83%BC-impress-gear/dp/4295015954/ref=pd_lpo_sccl_2/356-6513257-4582710?pd_rd_w=RQWZ2&content-id=amzn1.sym.514dbf04-9cdc-41ed-ac83-4d0f7ed7f867&pf_rd_p=514dbf04-9cdc-41ed-ac83-4d0f7ed7f867&pf_rd_r=RDD6YQFWXHT3YC2V7936&pd_rd_wg=vt4FX&pd_rd_r=316a508b-397c-40b6-8749-83b1e7be7477&pd_rd_i=4295015954&psc=1) にはトップKaggler達のインタビュー記事が多く掲載されていました。その中で上位入賞に重要と考えられる要素を表にまとめました。

| 項目 | 内容 | タイミング |
| --- | --- | --- |
| 問題設定、ルール、フォーマット、スケジュール、データセット、指標、提出物に関する情報の確認 | すべてに目を通す。 | \- |
| ディスカッションや共有コードのチェック | 公開情報全てに目を通す。序盤から終盤ずっとやる。 | 序盤～終盤 |
| ベースラインモデル作成 | 単純なパイプラインでつくる。最初は公開ノートブックを見ずに自力で作ると理解が深まる。 | 序盤 |
| データセットの可視化・EDA実施 | あらゆる質問に答えられるようにする。序盤は課題設定の理解のために、中盤以降は特徴量エンジニアリングのためにやる。 | 序盤～中盤 |
| 検証方法の確立 | ローカルスコアとリーダーボードのスコアが相関していたらOK【最重要】 | 序盤～中盤 |
| 特徴量エンジニアリング実施 | 作った特徴量は無駄にならないので序盤から中盤にやると◎ | 序盤～中盤 |
| 複数のモデルによる実験 | データセットに適したモデルを見つける。序盤から終盤ずっとやる。 | 序盤～終盤 |
| ハイパーパラメーターチューニング実施 | 序盤でチューニングする意味はないため、中盤から終盤に行う。 | 中盤～終盤 |
| 複数モデルのアンサンブル実施 | 序盤でする意味はないため、中盤から終盤に行う。 | 中盤～終盤 |
| 提出物の選択 | ローカルスコアが一番良いものとリーダーボードのスコアが一番良いものを合計2つ提出することが多い。 | 最終盤 |

私自身上記を実践することで、”CAFA 5 Protein Function Prediction”にて最終的なPublicスコアを1675チーム中9位の金メダル圏内で終えることができました。

ただし上記のコンペティションは追加データセットにより年末まで採点されPrivateスコアが確定するので、本記事執筆時点では、私自身が上位入賞したかは未確定です。そのため、本章のタイトル「上位入賞のハードルを下げる」は括弧書きとさせていただきました。  
（もしかしたら金メダルをきちんと獲得してKaggle Competitions Masterになってからこの記事を執筆した方がよかったかも）

## おわりに

Kaggleはハードルも多いですが、魅力的なコンテンツです。少しでも多くの方の、機械学習コンペティションに参加するきっかけが増えれば嬉しいです。  
また、本記事では、Kaggle Competitions についてフォーカスを当てましたが、DiscussionやNotebookへの投稿についてもハードルがあると感じています。日本人はCompetitionsの称号保持者数に対して、その他のDiscussion, Notebooks, Datasetsの称号保持者数が少ないみたいです。

言語が壁になっているのか、国民性なのか、ディスカッションへ投稿する人が少ないのかもしれませんね。

ディスカッションで金メダルを獲得したときに嬉しくなって、簡単にまとめたものがあるので良かったら、そちらもご覧いただければと思います。

本記事は以上です。皆様の良いKaggleライフを応援しております。

## 💡お知らせ(2023.12.01追記)

1人アドカレで生成AIについての記事を25件投稿します！  
この記事をご覧になられた方は、生成AIに興味がある方も多いと思いますので、よろしければご覧ください！

**生成AIアドベントカレンダー**

**記念すべき第1回の記事**

## 💡お知らせ（2023.12.15追記）

生成AIについての一人アドカレを完走しました！！！🙌  
見守ってくださった皆さま、本当にありがとうございました！

**『【祝・アドカレ完走！】生成AIについての記事を1人で25件投稿してみた！』**

## 💡お知らせ（2024.09.01追記）

Kaggle Masterに昇格しました！！！🙌

振り返り記事を書いたので、良かったらご覧いただければと思います！

[0](https://qiita.com/Isaka-code/items/#comments)

コメント一覧へ移動

[316](https://qiita.com/Isaka-code/items/3935cdb2a0bda331e07c/likers)

いいねしたユーザー一覧へ移動

348